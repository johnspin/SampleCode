# Jepsen Inspired Checker

## Task

For the purposes of this task, we're going to describe a simplified testing framework, inspired by Jepsen. This testing framework has a few concepts you'll want to understand. These are summarized here, with necessary detail included below under "Reference Documentation".

- Modules. Modules are the portions of the program that actually perform operations against the database. They can write data, read data, add new nodes, etc. They log the results of those operations to the test's history file. Our simple framework will use five modules.
- Operations. Operations are generated by Modules, and are logged to the test's history file. Each operation represents a single action by a Module, such as inserting a single row. Each operation should log the attempted action, and whether it succeeded or failed. This success/failure threshold is determined by the client executing the operation, and doesn't guarantee the operation was correct when viewing the entire system.
- Histories. A history file is a chronologically ordered list of operations. There is a one to one mapping of tests to history files. Each run of a test should generate a new history file, which will contain the output of every module that ran in that test.
- Checkers. After a test run completes, the checker is the program that parses the history file to decide if the test "passed" or not. It reads the history, and decides if the outcome of each operation is correct, given its knowledge of the state of the database at that time, and the previous operations that have occurred.

For this task, we'd like you to write a checker. We've included a set of history files generated by fictional test runs. Some of these histories represent passing tests, while others represent failing tests.

At this point, you may find it helpful to peruse the reference documentation at the bottom of this document.

Your checker should:

- Be able to take one or more text files as input. The text files will be histories.

- Validate whether the consistency level guarantees of reads and writes are met. If a query at a given Consistency Level, CL, requires N nodes to be in a 'LIVE' state, but <N nodes are in a 'LIVE' state, did the query fail? If >=N nodes were 'LIVE', did the query succeed?

- Validate whether data is eventually consistent.
  - If a value is read for a given key, was that value ever written previously?
  - There is no need to check if a written value is ever read.
  - There is no need to do more sophisticated consistency or serializability checking.

- Minimally, log whether a given history file is correct or not. Ideally, it should log the invalid operations, and the constraint that they failed. If the checker can take multiple histories as input, it should clearly output its analysis for each history. The output doesn't have to be well-formed, just human readable. Printing to stdout is acceptable.

## Deliverables

Please return all of the following, at your leisure:

- The source code for your checker
- Documentation on how to run, and if necessary, compile your checker. If relevant, please specify the version of the language your code is written in, e.g., Python 2.7.13 vs. Python 3.6.3.
- A write up explaining the overall design. Discuss the strengths and weaknesses of the Checker, the development process you took, and any problems you ran into. If you had more time, what would you change? What feature would you add next?
- Please include any feedback you may have on the task and the documentation, as well as approximately how long it took you. We aren't interested in this for assessment purposes, but so that we can improve on this screen for future applicants.

Feel free to attach these separately, or zipped in any non-proprietary format, preferably .tar.


## Reference Documentation

### Apache Cassandra

Even though our simplified testing framework is describing tests of Apache Cassandra, we've done our best to reduce the prerequisite knowledge of Apache Cassandra required. Here we will summarize what information we think is necessary.  Please note that this is a simplified model of Apache Cassandra for the purposes of this test; anywhere the details differ from the real-world behaviour, this documentation takes priority!

Apache Cassandra is a masterless, distributed database: a client does not connect to a single database process on a single host, but rather connects to any one of multiple database processes. We refer to each individual database process as a node, and the sum of all nodes as a cluster.

For the purposes of our tests Apache Cassandra is acting as a simple key-value store. All writes or reads will check for a single value at a single key, without any specification of tables or other schema information.

Note that Apache Cassandra is eventually consistent: this means that a read query against a specific key may not necessarily return the most recently written value for that key.

It is possible for an Apache Cassandra cluster to continue functioning, even if not all of the nodes are running. Because of this, we will track the state of the nodes in the cluster. A node can either be in a 'LIVE' or 'DEAD' state, which represents a running or stopped database process respectively.

We will assume a perfect network, so if a node is 'LIVE' it is guaranteed to successfully respond to all queries.

Both read and write queries from a client specify what's referred to as a Consistency Level. This is the number of nodes that must respond to a query in order for the query to be successful. We have simplified the Consistency Levels to just three:

- ONE: at least one node must be 'LIVE' to respond to a query
- QUORUM: at least one more than 50% of nodes, rounded down, must be 'LIVE' to respond to a query
- ALL: all nodes must be 'LIVE' respond to a query, i.e., the database will be unable to respond to an ALL query if even a single node is 'DEAD'

These values should be calculated out of the total number of nodes in a cluster.  For clarification on 'QUORUM', this means that a 4 node cluster will require 3 'LIVE' nodes; a 5 node cluster will also require 3 'LIVE' nodes; and a 6 node cluster will require 4 'LIVE' nodes.

### History Files

The history files are text files that contain ordered lists of operations, delimited with unix-style new lines. History files can contain blank lines, and lines that begin with a '#' character should be treated as comments, and ignored. Each operation is a dictionary of four keys: time, module, type, and action.

- 'time' is an integer value greater than zero. These do not correspond to real world times in any way: they are just abstractions, where a value t' that is greater than a value t indicates that t' is some time in the future.
  - Operations with the same time value occured at the same time.
  - Operation times within a given module are guaranteed to be monotonically increasing.
  - Operations across multiple modules can share the same time.
  - Operations are ordered by time within a history file, with the sole guarantee that time will never decrease.
  - Operations that occurred at the same time are ordered arbitrarily with respect to each other in the history file.

- 'module' indicates the client testing process that generated this operation. There are five modules: topology, write, read, live_nodes, and repair. The module indicates how the action key for this Operation should be parsed. This is explained in detail later, under 'action'.
  - The topology module governs making permanent changes to the number of nodes in the cluster. This includes the initial setup of the cluster, additions of new nodes, and removal of nodes. These changes can be of any size. It should be assumed that:
    - when the topology module increases the number of nodes in the cluster, the new nodes are in a 'LIVE' state
    - when the topology module decreases the number of nodes in the cluster, nodes in a 'DEAD' state are removed first, before any 'LIVE' nodes are removed. For example, in a 10 node cluster, with 6 'LIVE' nodes and 4 'DEAD' nodes, removing 5 nodes would result in a 5 node cluster with 5 'LIVE' nodes. Removing 2 nodes would have resulted in an 8 node cluster with 6 'LIVE' nodes and 2 'DEAD' nodes.
  - The write module represents attempted inserts to the database. This will log the requested Consistency Level, the key of the row written, and the value written to that row.
  - The read module represents attempted reads from the database. This will log the requested Consistency Level, the key of the row requested, and the value returned from that row.
  - The live_nodes module represents changes to the 'LIVE' or 'DEAD' states of the nodes in the cluster. The action key for these Operations will show the old number of 'LIVE' nodes, and then the new number of 'LIVE' nodes. It will never matter which nodes are in a 'LIVE' vs. 'DEAD' state, only the total count of each, relative to the total cluster size.
  - The repair module represents attempted repairs of the database. If you are not familiar with repair in Apache Cassandra, do not worry: this simply represents noise in the log.
  - The write and read modules report the state of the data in the database: it's this that you'll be validating.
  - The topology and live_nodes modules report the state of the cluster: if they succeed, then the data in 'action' is guaranteed to be correct.  Any mistakes in this data are mistakes in the construction of this tech screen, not the fictional database: please let us know about them!

- 'type' indicates whether the attempted Operation was successful or not. If it was successful, type will be 'ok' here, otherwise, type will be 'fail'. The action may still be logged, depending on the Operation, even if the type is 'fail'. If so, this represents the attempted action, rather than the executed action.
  - The topology, live_nodes, read, and repair modules do not change the state of the cluster in any way when they fail.
  - The write module will still change the state of the database, even if it fails. A fail here simply represents that the requested Consistency Level was not met. This means that a failed write of 5 to the key 'a' at a Consistency Level of QUORUM or ALL, can still result in a read of 5 for the key 'a', regardless of the Consistency Level of the read.

- 'action' indicates the attempted or executed action by the module. It will take different forms depending on the module. Action is optional: not all modules will log one. If logged, action will always be of the form "action={}", where the braces contain a tuple with either two or three values. Remember that for a failed operation, action refers to the _attempted_ action, and this does not mean the state of the cluster has actually changed. Please refer to the documentation for 'type' to see which modules change state even on failure.
  - The 'topology' module will have an action tuple containing two values. The first indicates the current size of the cluster, the second indicates the new size of the cluster. As mentioned earlier, this is guaranteed to be correct. Both values will be integers. Examples look like "action={0, 1}", "action={6, 3}", or "action={2, 3}".
  - The 'live_nodes' module will have an action tuple containing two values. The first indicates the current number of 'LIVE' nodes in the cluster. As mentioned earlier, this is guaranteed to be correct. The second indicates the new number of 'LIVE' nodes in the cluster. This can be any value between 0 and the total number of nodes in the cluster, inclusive. Examples look like "action={3, 0}", "action={2, 4}", or "action={3, 3}".
  - The 'write' module will have an action tuple containing three values. The first indicates the requested Consistency Level, which will be a string in single quotes, from the list of available Consistency Levels: 'ALL', 'QUORUM', 'ONE'. The second value will be the key of the row that we tried to insert. This will be a string in single quotes, and will be a single, lowercase, alphabetic character. The third and final value will be an integer, which is the value we tried to write to that row. These will always be between -128 and 127, inclusive. Examples look like "action={'ALL', 'a', 0}", "action={'QUORUM', 'c', -10}" or "action={'ONE', 'b', 5}".
  - The 'read' module will have an action tuple containing three values for a successful operation of type 'ok' or two values for a failed operation of type 'fail'. The first two values are identical in meaning and format as the first two values from the 'write' module. The third value, if present, indicates the value that was read from the database for the requested key. In a failed operation, there are only two values for action, because clearly we cannot have had a value returned in a failed read. Examples look like "action={'ALL', 'a', 0}", "action={'ONE', 'b'}", "action={'QUORUM', 'c', 0}".
  - The 'repair' module will never log an action.

A small set of examples can be found in the history file "examples.txt".
